{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Both Word2Vec and GloVe papers are reviewed.  \n",
    "\n",
    "2. ipynb files of Skipgram, Skipgram (NEG) and Glove have been modified and trained using following data:  \n",
    "Dataset: Reuters Corpus  \n",
    "Source: Natural Language Toolkit (NLTK)  www.nltk.org  \n",
    "Category Used: Livestock  \n",
    "The files are found in the same folder of main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare Skip-gram, Skip-gram negative sampling, GloVe models on training loss, training time, see table below.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use Word analogies dataset 3 to calucalte between syntactic and semantic accuracy, see table below.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Window Size | Training Loss | Training time | Syntactic Accuracy | Semantic accuracy |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "| Skipgram | 2 | 7.39 | 14m23s | 0 | 0 |\n",
    "| Skipgram (NEG) | 2 | 2.68 | 13m34s | 0 | 0 |\n",
    "| Glove | 2 | 3.63 | 3m26s | 0 | 0 |\n",
    "| Glove (Gensim) | 10 | -| - | 0 | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the correlation between model dot product and similarity metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Skipgram | NEG | GloVe | GloVe (gensim) | Y true |\n",
    "|----------|----------|----------|----------|----------|----------|\n",
    "|MSE |nan|nan|nan|||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Skipgram model shows the highest training loss, while Skipgram (NEG) has a lower loss, indicating that negative sampling might be contributing to more efficient learning. As to the trianing time, the Glove model is very faster compared to the Skipgram models, this could be due to its efficient handling of co-occurrence statistics.\n",
    "All models have been trained with a window size of 2, this is small number in real life training approach, which may be the reason for zero syntactic accuracy and semantic accuracy. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
